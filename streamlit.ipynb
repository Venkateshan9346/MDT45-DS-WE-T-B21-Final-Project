{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define paths\n",
        "MODEL_PATH = \"/content/image_caption_model.keras\"\n",
        "TOKENIZER_PATH = \"/content/tokenizer.pkl\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_model_and_tokenizer():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
        "    with open(TOKENIZER_PATH, \"rb\") as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_model_and_tokenizer()\n",
        "max_length = 34  # Set based on your training\n",
        "\n",
        "@st.cache_resource\n",
        "def get_feature_extractor():\n",
        "    base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)  # Output shape will be (None, 1536)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    return model\n",
        "\n",
        "\n",
        "feature_extractor = get_feature_extractor()\n",
        "\n",
        "def extract_features(image):\n",
        "    image = image.resize((300, 300))  # EfficientNetB3 expects 300x300 input\n",
        "    image = np.array(image)\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[..., :3]\n",
        "    image = preprocess_input(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    features = feature_extractor.predict(image)\n",
        "    features = np.reshape(features, (features.shape[0], -1))  # Flatten to (1, 1536)\n",
        "    return features\n",
        "\n",
        "# Generate caption\n",
        "def generate_caption(model, tokenizer, photo_features, max_length):\n",
        "    in_text = 'startseq'\n",
        "    for _ in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo_features, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None or word == 'endseq':\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "    final_caption = in_text.split()[1:]  # remove 'startseq'\n",
        "    return ' '.join(final_caption)\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"ðŸ–¼ï¸ Image Caption Generator\")\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    with st.spinner(\"Generating caption...\"):\n",
        "        photo_features = extract_features(image)\n",
        "        caption = generate_caption(model, tokenizer, photo_features, max_length)\n",
        "\n",
        "    st.success(\"Caption Generated!\")\n",
        "    st.write(\"**Caption:**\", caption)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpWkfkNxhSig",
        "outputId": "0d5c4f08-bb66-4d83-9f5f-3002f211e92b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPPhjIMohlq-",
        "outputId": "7e89386f-8d5a-42ab-ff34-f11c12c53984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.9.153\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kyour url is: https://shiny-news-begin.loca.lt\n"
          ]
        }
      ]
    }
  ]
}